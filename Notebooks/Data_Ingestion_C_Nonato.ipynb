{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "551e8c70-800a-409b-8d3d-de77830114f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Notebook Data Ingestion\n",
    "\n",
    "In this section, we will retrieve data from \"Datos abiertos\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "506da585-4657-427f-9323-770db3987ab7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Initial data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "17eb15bd-65e1-4ac9-b909-90dbe2d71576",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Paso 1: Descargar los datos con requests y leerlos en pandas\n",
    "import requests\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "url_secop = \"https://www.datos.gov.co/resource/rpmr-utcd.csv?$limit=100000\"\n",
    "url_men = \"https://www.datos.gov.co/resource/nudc-7mev.csv?$limit=100000\"\n",
    " \n",
    "# Descargar contenido\n",
    "response_secop = requests.get(url_secop)\n",
    "response_men = requests.get(url_men)\n",
    "\n",
    "# Convertir contenido a pandas usando StringIO\n",
    "df_secop_pd = pd.read_csv(StringIO(response_secop.text))\n",
    "df_men_pd = pd.read_csv(StringIO(response_men.text))\n",
    "\n",
    "# Convertir pandas a Spark\n",
    "df_secop = spark.createDataFrame(df_secop_pd)\n",
    "df_men = spark.createDataFrame(df_men_pd)\n",
    "\n",
    "# Mostrar en Databricks\n",
    "display(df_secop)\n",
    "display(df_men)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eea1c354-1e39-414a-84e6-6d6896299167",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_secop.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a7d5d83a-2a27-4ef7-b3d5-dcff48ac8d0f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE CATALOG main;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e2bda38a-6509-4f84-b31d-e5733c4e44ff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE SCHEMA IF NOT EXISTS main.diplomado_datos;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8ab3fc12-0ff9-45fe-9c98-d0d569d39ae3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"USE CATALOG main\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "66e0ab68-2149-4474-8565-c4c5776cfe23",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_secop.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"main.diplomado_datos.secop\")\n",
    "df_men.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"main.diplomado_datos.men_estadisticas\")\n",
    "\n",
    "print(\"¡Tablas guardadas exitosamente en el catálogo 'main', esquema 'diplomado_datos'!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d56a7379-c85b-4659-a51e-867d6f3669a3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Complete records download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1ef52a07-5cca-454f-84d2-2c29f22c2a6c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Consultar cuántos registros hay actualmente en el dataset SECOP\n",
    "count_url = \"https://www.datos.gov.co/resource/rpmr-utcd.json?$select=count(*)\"\n",
    "response = requests.get(count_url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    total_records = int(response.json()[0]['count'])\n",
    "    print(f\"Total de registros detectados: {total_records}\")\n",
    "else:\n",
    "    print(\"No se pudo obtener el total de registros. Usando valor por defecto.\")\n",
    "    total_records = 19446266  # Valor fijo como respaldo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9cb1cc29-1f2f-453b-8157-905e74e6200f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from pyspark.sql.functions import col, when\n",
    "\n",
    "limit = 100000\n",
    "offset = 100000\n",
    "\n",
    "def safe_cast(df, target_schema):\n",
    "    df_casted = df\n",
    "    for field in target_schema.fields:\n",
    "        name = field.name\n",
    "        dtype = field.dataType\n",
    "        if dtype.simpleString() in ['int', 'bigint', 'double', 'float', 'long']:\n",
    "            df_casted = df_casted.withColumn(\n",
    "                name,\n",
    "                when(col(name).rlike(\"^[0-9]+$\"), col(name).cast(dtype)).otherwise(None)\n",
    "            )\n",
    "        else:\n",
    "            df_casted = df_casted.withColumn(name, col(name).cast(dtype))\n",
    "    return df_casted\n",
    "\n",
    "start_time = time.time()  # Tiempo inicio\n",
    "\n",
    "while offset < total_records:\n",
    "    print(f\"Descargando registros desde {offset} hasta {offset + limit}...\")\n",
    "\n",
    "    url_secop = f\"https://www.datos.gov.co/resource/rpmr-utcd.csv?$limit={limit}&$offset={offset}\"\n",
    "    response_secop = requests.get(url_secop)\n",
    "\n",
    "    df_secop_pd = pd.read_csv(\n",
    "        StringIO(response_secop.text),\n",
    "        delimiter=',',\n",
    "        header=0,\n",
    "        dtype=str,\n",
    "        low_memory=False\n",
    "    )\n",
    "    \n",
    "    if df_secop_pd.empty:\n",
    "        print(\"No hay más datos para descargar.\")\n",
    "        break\n",
    "\n",
    "    df_secop_spark = spark.createDataFrame(df_secop_pd.astype(str))\n",
    "\n",
    "    target_schema = spark.table(\"main.diplomado_datos.secop\").schema\n",
    "\n",
    "    df_secop_aligned = safe_cast(df_secop_spark, target_schema)\n",
    "\n",
    "    df_secop_aligned.write.format(\"delta\") \\\n",
    "        .mode(\"append\") \\\n",
    "        .option(\"mergeSchema\", \"true\") \\\n",
    "        .saveAsTable(\"main.diplomado_datos.secop\")\n",
    "\n",
    "    print(f\"Datos del offset {offset} guardados.\")\n",
    "    offset += limit\n",
    "\n",
    "end_time = time.time()  # Tiempo fin\n",
    "\n",
    "total_seconds = end_time - start_time\n",
    "print(f\"Carga completa de SECOP en {total_seconds:.2f} segundos.\")\n",
    "\n",
    "# Opcional: formato legible horas, minutos, segundos\n",
    "hours = int(total_seconds // 3600)\n",
    "minutes = int((total_seconds % 3600) // 60)\n",
    "seconds = int(total_seconds % 60)\n",
    "\n",
    "print(f\"Tiempo total: {hours}h {minutes}m {seconds}s\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "757c34f6-f423-4167-bdc9-4de842eabf71",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Limpieza de datos"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5861728918384767,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Data_Ingestion_C_Nonato",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
